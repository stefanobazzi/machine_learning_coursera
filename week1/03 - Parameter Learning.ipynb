{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "\n",
    "Have some function $ J(\\theta_0, \\theta_1) $ and want to find $ \\theta_0, \\theta_1 $ to minimize $ J(\\theta_0, \\theta_1) $ (minimize error)\n",
    "\n",
    "* Start with some $ \\theta_0, \\theta_1 $\n",
    "* Keep changing $ \\theta_0, \\theta_1 $ to reduce $ J(\\theta_0, \\theta_1) $ until we hopeflly end up at a minimum\n",
    "\n",
    "#### Definition:     \n",
    "repeat until convergence     \n",
    "{\n",
    " \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $ \\theta_j = \\theta_j - \\alpha\\frac{\\partial }{\\partial \\theta_j}J(\\theta_0, \\theta_1) $ \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; (for $j = 0$ and $j = 1$)\n",
    "\n",
    "}\n",
    "         \n",
    "Important: update simultaneously (at the same time) all wights ($\\theta_j$) on each repetition\n",
    "\n",
    "$\\alpha = $ Learning Rate      \n",
    "\n",
    "\n",
    "On each iteration the weight will be updated following the gradient direction, so the function is going to find his minimum. Note: if the algortihm finds a local minimum the weights doesn't change anymore.\n",
    "\n",
    "\n",
    "If $\\alpha$ is too small, gradient descent can be slow    \n",
    "If $\\alpha$ is too large, gradient descent can overshoot the minimum. It may fail to converge, or even diverge.      \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent for Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the derivative terms for our cost function:\n",
    "\n",
    "$ \\frac{\\partial }{\\partial \\theta_j}J(\\theta_0, \\theta_1) = \n",
    "\\frac{\\partial }{\\partial \\theta_j}\\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})^2 =\n",
    "\\frac{\\partial }{\\partial \\theta_j}\\frac{1}{2m}\\sum_{i=1}^{m}(\\theta_0 + \\theta_1x^{(i)} - y^{(i)})^2\n",
    "$ \n",
    "\n",
    "Case $\\theta_0$ $(j = 0)$\n",
    "\n",
    "- $ \\frac{\\partial }{\\partial \\theta_0}J(\\theta_0, \\theta_1) =\n",
    "\\frac{1}{m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)}) $\n",
    "\n",
    "\n",
    "Case $\\theta_1$ $(j = 1)$\n",
    "\n",
    "- $ \\frac{\\partial }{\\partial \\theta_1}J(\\theta_0, \\theta_1) =\n",
    "\\frac{1}{m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient descent algorithm for hypothesis $ h_\\theta(x) = \\theta_0 + \\theta_1x $ become:\n",
    "\n",
    "repeat until convergence     {\n",
    " \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $ \\theta_0 = \\theta_0 - \\alpha\\frac{1}{m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)}) $ \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $ \\theta_1 = \\theta_1 - \\alpha\\frac{1}{m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})x^{(i)} $\n",
    "\n",
    "}\n",
    "\n",
    "update $\\theta_0$ and $\\theta_1$ simultaneously "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Batch\" Gradient Descent\n",
    "\n",
    "This method looks at every example in the entire training set on every step, and is called batch gradient descent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
