{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernels I\n",
    "\n",
    "Non lienar decision boundary (e.g circle like shape)     \n",
    "$\\theta_0 + \\theta_1x_1 + \\theta_2x_2 + \\theta_3x_1x_2 + \\theta_4x_1^2 + \\theta_5x2^2 + \\dots = $     \n",
    "$\\theta_0 + \\theta_1f_1 + \\theta_2f_2 + \\theta_3f_3 + \\theta_4f_4 + \\theta_5f_5 + \\dots $    \n",
    "\n",
    "$ f_1 = x_1, f_2 = x_2, f_3 = x_1x_2, f_4 = x_1^2, \\dots$\n",
    "\n",
    "Given $x$, compute new feature depending on proximity to landmark $l^{(1)}, l^{(2)}, l^{(3)}$\n",
    "\n",
    "given $x$: \n",
    " \n",
    "$f_1 = similarity(x,  l^{(1)}) = exp(- \\frac{\\|x -l^{(1)}\\|^2}{2\\sigma^2})$    \n",
    "$f_2 = similarity(x,  l^{(2)}) = exp(- \\frac{\\|x -l^{(2)}\\|^2}{2\\sigma^2})$         \n",
    "$f_3 = similarity(x,  l^{(3)}) = exp(- \\frac{\\|x -l^{(3)}\\|^2}{2\\sigma^2})$     \n",
    "\n",
    "\n",
    "$f_1 = similarity(x,  l^{(1)}) = exp(- \\frac{\\|x -l^{(1)}\\|^2}{2\\sigma^2}) = \n",
    "exp(- \\frac{\\sum_{j=1}^{n}(x_j -l_j^{(1)})^2}{2\\sigma^2}) $ \n",
    "\n",
    "if $x \\approx l^{(1)}$   $ f_1 \\approx exp(- \\frac{0^2}{2\\sigma^2}) \\approx 1 $      \n",
    "\n",
    "if $x$ is far from $l^{(1)}$   $ f_1 \\approx exp(- \\frac{\\text{(large number)}^2}{2\\sigma^2}) \\approx 0 $\n",
    "\n",
    "Predict \"1\" when  $\\theta_0 + \\theta_1f_1 + \\theta_2f_2 + \\theta_3f_3 \\geq 0$   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernels II\n",
    "\n",
    " How to find the landmarks?  \n",
    " \n",
    " \n",
    "Given  $(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \\dots, (x^{(m}), y^{(m)}))$     \n",
    "choose $l^{(1)} = x^{(1)}, l^{(2)} = x^{(2)}, \\dots, l^{(m)} = x^{(m)}$     \n",
    " \n",
    " \n",
    " Given example $x$:    \n",
    "$ f_1 = similarity(x, l^{(1)})$,       \n",
    "$f_2 = similarity(x, l^{(2)})$,    \n",
    "$\\vdots$    \n",
    "\n",
    "For training example  $(x^{(i)}, y^{(i)})$\n",
    "- $ f_1^{(i)} = sim(x^{(i)}, l^{(1)})$\n",
    "- $ f_2^{(i)} = sim(x^{(i)}, l^{(2)})$\n",
    "- $\\vdots$  \n",
    "- $ f_m^{(i)} = sim(x^{(i)}, l^{(m)})$\n",
    "\n",
    "#### SVM with Kernels\n",
    "\n",
    "Hypothesis; Givenn $x$, compute features $ f \\in \\mathbb{R^{n+1}}$\n",
    "\n",
    "Predict \"$Y=1$\" if $\\theta^Tf \\geq 0$\n",
    "\n",
    "Trainig:   \n",
    "\n",
    "$ \\min_\\limits{\\theta}  = C\\sum_{i=1}^{m}[y^{(i)}cost_1(\\theta^Tf^{(i)}) + (1 - y^{(i)})cost_0(\\theta^Tf^{(i)})] + \\frac{1}{2}\\sum_{i=1}^{m}\\theta_j^2 $\n",
    "\n",
    "##### ChooseSVM parameters:\n",
    "\n",
    "$C = \\frac{1}{\\lambda}$      \n",
    "Large C: Lower bias, high variance (small $\\lambda$)     \n",
    "Small C: Higher bias, low variance (large $\\lambda$)\n",
    "\n",
    "$\\sigma^2$     \n",
    "Large $\\sigma^2$: Features $f_i$ vary more smoothly. High bias, lower variance.    \n",
    "Small $\\sigma^2$: Features $f_i$ vary less smoothly. Lower bias, higher variance.    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
