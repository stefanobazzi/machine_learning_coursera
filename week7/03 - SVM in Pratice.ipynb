{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a SVM\n",
    "\n",
    "Use a SVM software package (already optimized) to find $\\theta$ parameters.\n",
    "\n",
    "Need to specify:\n",
    "- Choice of paramater C\n",
    "- Choice of kernel (similarity function)\n",
    "\n",
    "E.g no kernel(\"linera kernel\")    \n",
    "Predict \"y = 1\" if $\\theta^Tx \\geq 0$ \n",
    "\n",
    "Gaussian kernel        \n",
    "$f_i = exp(- \\frac{\\|x -l^{(i)}\\|^2}{2\\sigma^2})$, where $l^{(i)} = x^{(i)}$    \n",
    "Need to choose $\\sigma^2$\n",
    "\n",
    "#### Kernel (similarity) function\n",
    "Note: perfomr feature scaling before using the gaussian kernel\n",
    "function f = kernel(x1, x2)    \n",
    "f = $exp(- \\frac{\\|x1 -x2\\|^2}{2\\sigma^2})$    \n",
    "return  \n",
    "\n",
    "$\\|x1 -l\\|^2$ -> $v= x -l$       \n",
    "$\\|v\\|^2 = v_1^2 + v_2^2 + \\dots v_n^2 = (x_1 -l_1)^2 + (x_2 -l_2)^2 + \\dots + (x_n -l_n)^2$\n",
    "\n",
    "#### Other choices of kernel\n",
    "\n",
    "Not all similarity functions make valid kernels. (Need to satisfy techincal condition called \"Mercer's Theorem\" to make sure SVM packages otimizatinos run correctly and do not diverge).\n",
    "\n",
    "Many off-the-shelf kernels:\n",
    "- Plynomial kernel $(x^Tl + \\text{constant})^{\\text{degree}}$\n",
    "- more esoteric: String kernel, chi-square kernel, histogram, intersection kernel\n",
    "\n",
    "#### Multi-class classification\n",
    "\n",
    "Many SVM packages already have built.in multi-class classification functionality.   \n",
    "Otherwise, use one-vs-all method.(Train $k$ SVMs, one to distinguish $y = i$ form the rest, for $i = 0, 1, \\dots, K$ get \n",
    "$\\theta^{(1)}, \\theta^{(2)}, \\dots, \\theta^{(K)}$     \n",
    "Pick class $i$ with largest $(\\theta^{(i)})^Tx$\n",
    "\n",
    "#### Logisti regression vs. SVM\n",
    "\n",
    "$n$ = number of features ($x \\in \\mathbb{R}^{n+1}$), $m$ = number of training examples    \n",
    "- if $n$ is large (relative fo $m$) (e.g : $n \\geq m, n= 10,000, m = 10 \\dots 1000 $)   \n",
    "    Use logistic regresssion, or SVM without a kernel (\"linear kernel\")\n",
    "\n",
    "- If $n$ is small, $m$ is intermediate ( n= 1-1000, m = 10-10000 ):\n",
    "    Use SVM with gaussian kernel\n",
    "   \n",
    "- If $n$ is small, $m$ is large ( n= 1-1000, m = 50,000+ ):\n",
    "    Create/add more features, then use logistic reggression or SVM without a kernel\n",
    "\n",
    "Neural network likely to work wll for most of these settings, but may be slower to train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
