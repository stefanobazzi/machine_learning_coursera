{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function\n",
    "\n",
    "Trainig set: $ \\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \\dots, (x^{(m)}, y^{(m)})\\} $\n",
    "\n",
    "$m$ examples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$x \\in \\begin{bmatrix} x_0 \\\\ x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix} $ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$ x_0 = 1, y \\in \\{0,1\\}$\n",
    "\n",
    "$h_\\theta(x) = \\frac{1}{1 +e^{-\\theta^Tx}}$\n",
    "\n",
    "How to choose parmeters $\\theta$?\n",
    "\n",
    "$h_\\theta(x) = \\frac{1}{1 +e^{-\\theta^Tx}}$\n",
    "\n",
    "$ J(\\theta) = \\frac{1}{2m}\\sum_{i=0}^{m}(h_\\theta(x^{(i)}) - y^{(i)})^2$\n",
    "\n",
    "this function with the logistic function is not convex! the mean square error with logistic function si wavy causing maany local optima.  \n",
    "\n",
    "#### Logistic regression cost function\n",
    "\n",
    "$\\text{Cost}(h_\\theta(x), y) = \n",
    "\\begin{cases}\n",
    "-\\log(h_\\theta(x)) & \\text{if } y = 1 \\\\\n",
    "-\\log(1 - h_\\theta(x)) & \\text{if } y = 0 \\\\\n",
    "\\end{cases}\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplified Cost Function adn Gradient Descent\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression cost function\n",
    "\n",
    "$ J(\\theta) = \\frac{1}{2m}\\sum_{i=0}^{m}Cost(h_\\theta(x^{(i)}), y^{(i)})$\n",
    "\n",
    "$Cost(h_\\theta(x), y) = \n",
    "\\begin{cases}\n",
    "-\\log(h_\\theta(x)) & \\text{if } y = 1 \\\\\n",
    "-\\log(1 - h_\\theta(x)) & \\text{if } y = 0 \\\\\n",
    "\\end{cases}$\n",
    "\n",
    "The cost function can be written in more comapct way as:\n",
    "\n",
    "$Cost(h_\\theta(x), y) = -y\\log(h_\\theta(x)) - (1 - y)\\log(1 - h_\\theta(x))$\n",
    "\n",
    "if $ y = 1 \\Rightarrow Cost(h_\\theta(x), y) = -\\log(h_\\theta(x))$\n",
    "\n",
    "if $ y = 0 \\Rightarrow Cost(h_\\theta(x), y) = -\\log(1 - h_\\theta(x))$\n",
    "\n",
    "\n",
    "$ J(\\theta) = \\frac{1}{2m}\\sum_{i=0}^{m}Cost(h_\\theta(x^{(i)}), y^{(i)}) = \n",
    "-\\frac{1}{m}[\\sum_{i=0}^{m}y^{(i)}\\log(h_\\theta(x^{(i)})) + (1 - y^{(i)})\\log(1 - h_\\theta(x^{(i)}))]\n",
    "$\n",
    "\n",
    "To fit parameters $\\theta$ we want to find the $min_\\theta$ of $J(\\theta)$\n",
    "\n",
    "#### Gradient Descent\n",
    "\n",
    "$ J(\\theta) =  -\\frac{1}{m}\\sum_{i=0}^{m}[y^{(i)}\\log(h_\\theta(x^{(i)})) + (1 - y^{(i)})\\log(1 - h_\\theta(x^{(i)}))] $\n",
    "\n",
    "Repeat {\n",
    " \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $ \\theta_j := \\theta_j - \\alpha\\frac{\\partial }{\\partial \\theta_j}J(\\theta) $ \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Simultaneously update for every $\\theta_j$\n",
    "\n",
    "}\n",
    "\n",
    "Repeat {\n",
    " \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $ \\theta_j := \\theta_j - \\alpha\\sum_{i=0}^{m}(h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)}$ \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Simultaneously update for every $\\theta_j$\n",
    "\n",
    "}\n",
    "\n",
    "Looks identical to linear regression! Actually is not exaclty the same, the only difference is the definition of $h_\\theta(x) = \\frac{1}{1 +e^{-\\theta^Tx}}$\n",
    "\n",
    "\n",
    "A vectorized implementation is:\n",
    "\n",
    "$h = g(X\\theta)$\n",
    "\n",
    "$J(\\theta) = \\frac{1}{m}(-y^Tlog(h)-(1-y)^Tlog(1-h)$\n",
    "\n",
    "Repeat {\n",
    " \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $\\theta := \\theta - \\frac{\\alpha}{m}X^T(g(X\\theta) - \\vec{y})$\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Optimization\n",
    "\n",
    "Gradient descent is not the only optimization algorithm, eg.:\n",
    "* Coniugate gradient\n",
    "* BFGS\n",
    "* L-BFGS\n",
    "\n",
    "Advantages:\n",
    "* NOn need to manually pick $\\alpha$\n",
    "* Often converge faster than gradient descent\n",
    "\n",
    "Divantages:\n",
    "* More complex\n",
    "\n",
    "\n",
    "Example:\n",
    "$\\theta = \n",
    "\\begin{bmatrix}\n",
    "\\theta_1 \\\\\n",
    "\\theta_2\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$J(\\theta) = (\\theta_1 - 5)^2 + (\\theta_2 - 5)^2$\n",
    "\n",
    "\"Conjugate gradient\", \"BFGS\", and \"L-BFGS\" are more sophisticated, faster ways to optimize Î¸ that can be used instead of gradient descent. We suggest that you should not write these more sophisticated algorithms yourself (unless you are an expert in numerical computing) but use the libraries instead, as they're already tested and highly optimized. Octave provides them\"\n",
    "\n",
    "On octave, write a function that returns $J(\\theta)$ and the gradient:\n",
    "\n",
    "function [jVal, gradient] = costFunction(theta)      \n",
    "&nbsp;&nbsp;&nbsp;&nbsp  jVal = [...code to compute J(theta)...];         \n",
    "&nbsp;&nbsp;&nbsp;&nbsp  gradient = [...code to compute derivative of J(theta)...];       \n",
    "end      \n",
    "\n",
    " \n",
    "options = optimset('GradObj', 'on', 'MaxIter', 100);      \n",
    "initialTheta = zeros(2,1);     \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;   [optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options);      \n",
    "   \n",
    "   \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
