{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problem of Overfitting\n",
    "\n",
    "* Underfitting or \"high bias\": the model is too simple (e.g use linear model to represent a quadratic model)\n",
    "* Overfitting or \"high variance\": the model is too complex (e.g use fifth order polynomial model to represent a quadratic model)\n",
    "\n",
    "\n",
    "#### Addressing overfitting\n",
    "\n",
    "Options:\n",
    "1. Reduce number of features.\n",
    "    * Manulally select wich features to keep.\n",
    "    * Model selection algorithm (later in course)\n",
    "2. Regularization.\n",
    "    * Keep all features, but reduce magnitude/values of parameters $\\theta_j$.\n",
    "    * Works well when we have a lot of features, each of wich contributes a bit to predicting $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function\n",
    "\n",
    "#### Intuition\n",
    "The idea is to choose (or find) some parameters and make it small, so they contribute less to the hypothesis approximation.\n",
    "\n",
    "e.g \n",
    "* correct hypohtesis : $h_\\theta(x) = \\theta_0 + \\theta_1x + \\theta_2x^2$\n",
    "* current hypothesis : $h_\\theta(x) = \\theta_0 + \\theta_1x + \\theta_2x^2 \\theta_3x^3 + \\theta_4x^4$\n",
    "\n",
    "We want to remove the influence of $\\theta_3$ and $\\theta_4$ terms and so add an addittional term to error function to \"force\" $\\theta_3$ and $\\theta_4$ to be small\n",
    "\n",
    "$ min \\frac{1}{2m}\\sum_{i=0}^{m}(h_\\theta(x^{(i)}) - y^{(i)})^2 + 1000\\theta_3^2 + 1000\\theta_4^2$\n",
    "\n",
    "To get a low error  $\\theta_3$ and $\\theta_4$ will be about zero\n",
    "\n",
    "#### Regularization\n",
    "Small values for parameters $\\theta_0, \\theta_1, \\dots, \\theta_n$\n",
    "* Simpler hypothesis\n",
    "* Less prone to overfitting\n",
    "the regularuzation term gives a smoother shape to the hypothesis\n",
    "\n",
    "\n",
    "$J(\\theta) = \\frac{1}{2m}\\sum_{i=0}^{m}(h_\\theta(x^{(i)}) - y^{(i)})^2 + \\lambda\\sum_{i=0}^{n}\\theta_j^2$\n",
    "\n",
    "$\\lambda\\sum_{i=0}^{n}\\theta_j^2$ : Regualarization parameter\n",
    "\n",
    "If the $\\lambda$ parameter is too large (e.g $\\lambda = 10^{10}$) the train goes to underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
