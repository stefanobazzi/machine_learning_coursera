{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Formulation\n",
    "\n",
    "Example: Predicting Movie Ratings  \n",
    "\n",
    "User rates using zero to five starts\n",
    "\n",
    "$n_u$ = no. users    \n",
    "$n_m$ = no. movies      \n",
    "$r(i,j)$ = 1 if user $j$ has rated movie $i$     \n",
    "$y(i,j)$ = rating given by user $j$ fo movie $i$ (defined only if $r(i,j)$ = 1 )\n",
    "\n",
    "Recommended system try to predict values where user do not rate the film, so an algorithm that can automatically fill the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Based Recommendations\n",
    "\n",
    "How to predict the missing values? (E.g missing film rate)    \n",
    "Need some features about data e.g. $x_1$ = romance, $x_2$ = action for every film\n",
    "\n",
    "For each user $j$, learn a parmaeter $\\theta^{(j)} \\in \\mathbb{R}^n$. Predict user $j$ as rating movie $i$ with $(\\theta^{(j)})^Tx^{(i)}$ stars.\n",
    "\n",
    "#### Problem formulation\n",
    "\n",
    "$r(i,j)$ = 1 if user $j$ has rated movie $i$     \n",
    "$y(i,j)$ = rating given by user $j$ fo movie $i$    \n",
    "$\\theta^{(j)}$ = parameter vector for user $j$    \n",
    "$x^{(j)}$ = feature vector for movio $i$    \n",
    "For user $j$, movie $i$, predict rating $(\\theta^{(j)})^Tx^{(i)}$    \n",
    "\n",
    "$m^{(j)}$ = no. of movies rated by user $j$    \n",
    "To learn $\\theta^{(j)}$      \n",
    "\n",
    "$\\displaystyle \\min_{\\theta^{(j)}} = \\frac{1}{2m^{(i)}} \\displaystyle \\sum_{i:r(i,j)=1}( (\\theta^{(j)})^Tx^{(i)} -y^{(i, j)} )^2 +\n",
    "\\frac{\\lambda}{2m^{(i)}} \\displaystyle \\sum_{k=1}^{n}(\\theta_k^{(j)})^2 $\n",
    "\n",
    "we can get rid of term $m^{(i)}$, so \n",
    "\n",
    "to learn $\\theta^{(j)}$  (parameter for user $j$):\n",
    "\n",
    "$\\displaystyle \\min_{\\theta^{(j)}} = \\frac{1}{2} \\displaystyle \\sum_{i:r(i,j)=1}( (\\theta^{(j)})^Tx^{(i)} -y^{(i, j)} )^2 +\n",
    "\\frac{\\lambda}{2} \\displaystyle \\sum_{k=1}^{n}(\\theta_k^{(j)})^2 $\n",
    "\n",
    "To learn $\\theta^{(1)}, \\theta^{(2)}, \\dots, \\theta^{(n_u)}$:\n",
    "\n",
    "\n",
    "$\\displaystyle \\min_{\\theta^{(1)},\\dots, \\theta^{(n_u)}} = \n",
    "\\frac{1}{2} \\displaystyle \\sum_{j=1}^{n_u} \\sum_{i:r(i,j)=1}( (\\theta^{(j)})^Tx^{(i)} -y^{(i, j)} )^2 +\n",
    "\\frac{\\lambda}{2} \\displaystyle \\sum_{j=1}^{n_u} \\sum_{k=1}^{n}(\\theta_k^{(j)})^2 $ = \n",
    "$\\displaystyle \\min_{\\theta^{(1)},\\dots, \\theta^{(n_u)}} J(\\theta^{(1)},\\dots, \\theta^{(n_u)})$\n",
    "\n",
    "\n",
    "Gradient descent update\n",
    " \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $ \\theta_k^{(j)} := \\theta_k^{(j)} - \\alpha\\displaystyle\\sum_{i:r(i,j)=1}( (\\theta^{(j)})^Tx^{(i)} -y^{(i, j)} )x_k^{(i)}$ for $k = 0$\n",
    " \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $ \\theta_k^{(j)} := \\theta_k^{(j)} - \\alpha \\Big(\\displaystyle\\sum_{i:r(i,j)=1}( (\\theta^{(j)})^Tx^{(i)} -y^{(i, j)} )x_k^{(i)} + \\lambda\\theta_k^{(j)} \\Big)$ for $k \\neq 0$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
